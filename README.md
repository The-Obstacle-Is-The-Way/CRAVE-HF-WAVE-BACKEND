# ğŸŒŠ CRAVE WAVE (Trinity Backend): Vertical AI Optimization for Craving Intelligence

## ğŸŒŸ Overview  
CRAVE WAVE (Trinity Backend) is a modular, Dockerized FastAPI application built with clean architecture principles. It is designed to track and analyze user cravings and integrates multiple external services, including:  

- ğŸ›¢ **PostgreSQL** for structured data storage  
- ğŸ§  **Pinecone** for vector-based retrieval 
- ğŸ¤– **Llama 2 with LoRA integration** for AI-powered insights

This repository demonstrates an end-to-end systemâ€”from initial setup and database migrations to AI model inference with LoRA adapters.  
* ğŸ”— Frontend (SwiftUI + SwiftData + MVVM) â†’ [crave-trinity-frontend](https://github.com/Crave-Trinity/crave-trinity-frontend)
* ğŸ”— Backend (FastAPI + PostgreSQL + Pinecone + Llama 2) â†’ [crave-trinity-backend](https://github.com/Crave-Trinity/crave-trinity-backend)

---

âš ï¸ Disclaimer: CRAVE intends to provide analytical insights based on user-logged cravings data.

It will not offer medical predictions, diagnoses, or treatment prior to FDA SaMD approval.
Any behavioral insights should be viewed as informational only, and users should consult a healthcare professional for medical or therapeutic guidance.

---

![CRAVE Architecture](docs/crave-trinity-architecture-fixed.svg)

## ğŸŒŠ Vision
CRAVE-WAVE strives to be the worldâ€™s first self-optimizing craving intelligence systemâ€”a backend powered by Vertical AI, ensuring that craving personas, retrieval strategies, and inference evolve dynamically as moat and user behavior shift.

ğŸ§  LoRA Persona Hot-Swapping: 
* AI doesnâ€™t just retrieve user insightsâ€”it ensures that only the most relevant craving personas are running at any given time. Unused personas are dynamically offloaded, and active personas are auto-optimized based on real-world craving triggers.

ğŸ” RAG Time Compression & Sequencing: 
* Forget static retrieval pipelines. CRAVEâ€™s retrieval strategy adapts over time, ensuring that recent cravings are prioritized, while older patterns are compressed & summarized intelligently.

âš¡ Self-Tuning GPU & VRAM Optimization: 
* The system continuously monitors hardware utilizationâ€”adjusting VRAM allocation, inference batching, and persona swapping to ensure real-time efficiency without bottlenecks.

ğŸš€ Autonomous AI Fine-Tuning: 
* Instead of relying on human intervention, CRAVE uses Reinforcement Learning (RLHF) to iteratively refine LoRA persona deployment and retrieval logic. Itâ€™s an AI system that learns how to optimize itselfâ€”so performance improves continuously.
  
---

ğŸ”— The Core AI Infrastructure

1ï¸âƒ£ Vertical AI Agent for Autonomous LoRA Persona Management
* âœ” Monitors real-world craving events and dynamically deploys, swaps, or removes LoRA fine-tuned personas in real time.
* âœ” Hot-swap framework to keep only the most relevant craving personas in active VRAM.
* âœ” Self-improving persona selection via Reinforcement Learning (RLHF) to enhance accuracy over time.

2ï¸âƒ£ Adaptive RAG Retrieval & Time Compression
* âœ” Recency-Weighted Memory: Prioritizes recent cravings but summarizes long-term trends to prevent AI bloating.
* âœ” Dynamic Retrieval Scaling: Adjusts vector DB query depth & response relevance based on past user interactions.
* âœ” Time-Aware Insight Caching: Creates compressed trend markers so retrieval remains fast & cost-efficient.

3ï¸âƒ£ Self-Tuning AI Inference Optimization
* âœ” Real-Time VRAM/CPU Monitoring: Adjusts hardware usage based on demand.
* âœ” Quantization & Adaptive Batching: Ensures LLaMA/LoRA models run at peak efficiency with minimal compute lag.
* âœ” Scales automatically with user volume: Prevents GPU bottlenecks by auto-managing active inference nodes.

---

## ğŸ— Architecture & Batches  

The project was developed with AI-acceleration & basecode abstraction through modular batches, breaking the development process into structured steps:  

### ğŸ”¹ Batch 1 â€“ Initial Setup  
ğŸ“Œ Clone the repository, install dependencies, and configure the environment.  
ğŸ”§ Initialize **PostgreSQL** and apply **Alembic** database migrations.  
ğŸ“‚ **Key files:** `.env`, `requirements.txt`, `alembic.ini`  

### ğŸ”¹ Batch 2 â€“ Backend & Database Integration  
ğŸ›  Develop **FastAPI** REST endpoints following **clean architecture**.  
ğŸ“Š Implement **database models, repositories, and use-case layers** for craving tracking.  
ğŸ“‚ **Key files:** `app/api/`, `app/core/`, `app/infrastructure/database/`  

### ğŸ”¹ Batch 3 â€“ External Services Integration  
ğŸ“¡ Connect to **Pinecone** for **vector storage & retrieval**.  
ğŸ¤– Integrate **OpenAI embeddings** for craving analysis.  
ğŸ“‚ **Key files:** `app/infrastructure/vector_db/`, `app/infrastructure/external/openai_embedding.py`  

### ğŸ”¹ Batch 4 â€“ Llama 2 with LoRA Integration  
ğŸ¦™ Load and fine-tune **Llama 2** using **LoRA adapters**.  
ğŸ” Deploy AI inference endpoints for **craving insights**.  
ğŸ“‚ **Key files:** `app/models/llama2_model.py`, `app/infrastructure/llm/llama2_adapter.py`  

---

## ğŸ“‚ File Structure  

```plaintext
jj@DESKTOP-L9V85UA:/mnt/c/Users/JJ/Desktop/CRAVE/crave_trinity_backend$ tree -I ".git"
.
################################################################################
#                                                                              
#  "I understand there's a guy inside me who wants to lay in bed,              
#   smoke weed all day, and watch cartoons and old movies.                     
#   My whole life is a series of stratagems to avoid, and outwit, that guy."  
#                                                                              
#   - Anthony Bourdain                                                         
#                                                                              
#   CRAVE: Because understanding our cravings shouldn't be complicated ğŸ«
#                                                                              
################################################################################
#
#
#
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ alembic.ini
â”œâ”€â”€ app
â”‚Â Â  â”œâ”€â”€ api
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dependencies.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ endpoints
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ai_endpoints.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ craving_logs.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dependencies.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ health.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ user_queries.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ main.py
â”‚Â Â  â”œâ”€â”€ config
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ settings.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ logging.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ settings.py
â”‚Â Â  â”œâ”€â”€ container
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Dockerfile
â”‚Â Â  â”‚Â Â  â””â”€â”€ ecs_config.yaml
â”‚Â Â  â”œâ”€â”€ core
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ entities
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ craving.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ user.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ services
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ analytics_service.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ embedding_service.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ lora_manager.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ pattern_detection_service.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ rag_service.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ use_cases
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ generate_craving_insights.py
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ ingest_craving.py
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ manage_metadata.py
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ process_query.py
â”‚Â Â  â”‚Â Â      â””â”€â”€ search_cravings.py
â”‚Â Â  â”œâ”€â”€ infrastructure
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ auth
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ auth_service.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ oauth_provider.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ user_manager.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ database
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ models.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ migrations
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ README
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ env.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ env.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ script.py.mako
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ versions
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â      â”œâ”€â”€ 200c7d532370_initial_tables_users_cravings.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â      â””â”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â          â””â”€â”€ 200c7d532370_initial_tables_users_cravings.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ models.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ repository.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ external
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ langchain_integration.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ openai_embedding.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ llm
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ huggingface_integration.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ llama2_adapter.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ lora_adapter.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ vector_db
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ pinecone_client.py
â”‚Â Â  â”‚Â Â      â””â”€â”€ vector_repository.py
â”‚Â Â  â””â”€â”€ models
â”‚Â Â      â””â”€â”€ llama2_model.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docs
â”‚Â Â  â”œâ”€â”€ architecture.md
â”‚Â Â  â””â”€â”€ roadmap.md
â”œâ”€â”€ infra
â”‚Â Â  â”œâ”€â”€ aws
â”‚Â Â  â”œâ”€â”€ docker
â”‚Â Â  â””â”€â”€ k8s
â”œâ”€â”€ main.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â””â”€â”€ tests
    â”œâ”€â”€ integration
    â”‚Â Â  â”œâ”€â”€ test_ai_endpoints.py
    â”‚Â Â  â”œâ”€â”€ test_api.py
    â”‚Â Â  â””â”€â”€ test_craving_search_api.py
    â”œâ”€â”€ test_basic.py
    â””â”€â”€ unit
        â”œâ”€â”€ test_auth_service.py
        â”œâ”€â”€ test_ingest_craving.py
        â”œâ”€â”€ test_lora_adapter.py
        â”œâ”€â”€ test_rag_service.py
        â””â”€â”€ test_search_cravings.py

30 directories, 62 files
```
---

## âš¡ Quick Start  

### âœ… Prerequisites  

Before you begin, ensure you have the following installed:  

- ğŸ³ Docker & Docker Compose for containerized setup  
- ğŸ Python 3.11 (if running locally)  
- ğŸ¤— Hugging Face CLI (if using private models, run `huggingface-cli login`)  

### ğŸ“¥ Clone the Repository  

```bash
git clone git@github.com:The-Obstacle-Is-The-Way/crave-trinity-backend.git
cd crave-trinity-backend
```

### ğŸ”§ Configure Environment Variables  

Create a `.env` file in the project root with the necessary credentials:  

```env
SQLALCHEMY_DATABASE_URI=postgresql://postgres:password@db:5432/crave_db
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENV=us-east-1-aws
PINECONE_INDEX_NAME=crave-embeddings
OPENAI_API_KEY=your_openai_api_key_here
```

### ğŸ— Build & Run with Docker Compose  

```bash
docker-compose up --build
```

This will:  
âœ… Build the **FastAPI** backend container  
âœ… Start the **PostgreSQL** database  
âœ… Expose ports **8000** (API) & **5432** (Database)  

### ğŸ”„ Run Database Migrations  

Inside the container (or locally, if configured):  

```bash
alembic upgrade head
```

This ensures the **database schema** is up to date.  

---

## ğŸ§ª Testing the Application  

### ğŸ”¬ API Endpoints  

Once running, test the **craving logging API** with:  

```bash
curl -X POST -H "Content-Type: application/json" \
-d '{"user_id":1, "description":"Chocolate craving", "intensity":8}' \
http://localhost:8000/cravings
```

### ğŸ“¡ Pinecone Integration  

Inside the **FastAPI** container, verify the Pinecone index:  

```bash
docker exec -it crave_trinity_backend-fast-api-1 python -c \
"from app.infrastructure.vector_db.pinecone_client import init_pinecone; \
init_pinecone(); import pinecone; print('List of indexes:', pinecone.list_indexes())"
```

Ensure `crave-embeddings` exists and is ready for use.  

### ğŸ¤– Run Llama 2 with LoRA Inference (Batch 4)  

```bash
docker exec -it crave_trinity_backend-fast-api-1 python app/models/llama2_model.py
```

This loads **Llama 2 + LoRA adapters** and runs a **test inference prompt**.  

---

## ğŸ›  Technical Details  

- ğŸ³ **Dockerized Setup**  
  - The backend is containerized with Python 3.11-slim for efficiency.  

- ğŸ›¢ **Database**  
  - Uses **PostgreSQL**, managed via **Alembic** migrations.  

- ğŸ“¡ **External Services**  
  - **Pinecone** for vector storage & retrieval.  
  - **OpenAI** for text embeddings and craving analysis.  

- ğŸ¤– **AI Model (Batch 4)**  
  - Llama 2 runs via Hugging Face Transformers.  
  - LoRA adapters fine-tune AI insights with PEFT.  

---

## ğŸ›£ Roadmap & Future Enhancements  

ğŸ”œ **Batch 5** â€“ Analytics dashboard & craving trend visualization  
ğŸ“Š **Batch 6** â€“ Performance optimizations (GPU inference, rate limiting)  
ğŸ”’ **Security Enhancements** â€“ OAuth, data anonymization, and logging improvements  
ğŸš€ **Scaling** â€“ Kubernetes deployment (`infra/k8s`)  

---

ğŸŒ Why This Changes Everything

* ğŸ’¥ Static AI is dead.
* ğŸ’¥ Self-learning, self-optimizing AI is the future.
* ğŸ’¥ CRAVE-WAVE is that future.

ğŸ’¡ We donâ€™t ask if something is possible. We build until it is.

* âš¡ AI that doesnâ€™t just process cravingsâ€”it evolves in real time.
* âš¡ Welcome to the first self-optimizing craving intelligence system.
* âš¡ Welcome to CRAVE-WAVE.

ğŸ”¥ Get Involved & Contribute
This is a revolution in craving intelligence.

ğŸ“œ GitHub: Crave-Trinity Backend
ğŸ“¢ Twitter: Coming Soon.
ğŸ™ YC Demo Day: Stay tuned.

---

* ğŸ”— Frontend (SwiftUI + SwiftData + MVVM) â†’ [crave-trinity-frontend](https://github.com/Crave-Trinity/crave-trinity-frontend)
* ğŸ”— Backend (FastAPI + PostgreSQL + Pinecone + Llama 2) â†’ [crave-trinity-backend](https://github.com/Crave-Trinity/crave-trinity-backend)

---

âš ï¸ Disclaimer: CRAVE intends to provide analytical insights based on user-logged cravings data.

It will not offer medical predictions, diagnoses, or treatment prior to FDA SaMD approval.
Any behavioral insights should be viewed as informational only, and users should consult a healthcare professional for medical or therapeutic guidance.

---

## ğŸ¤ Contributing  

1ï¸âƒ£ **Fork** the repository  
2ï¸âƒ£ **Create** a feature branch (`git checkout -b feature/your-feature`)  
3ï¸âƒ£ **Commit** your changes (`git commit -m "Added feature X"`)  
4ï¸âƒ£ **Push** & open a pull request  

---

## ğŸ“œ License  

This project is licensed under the **MIT License**.  
